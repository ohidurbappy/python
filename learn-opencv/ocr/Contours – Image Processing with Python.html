<!DOCTYPE html>
<!-- saved from url=(0055)https://datacarpentry.org/image-processing/09-contours/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="last-modified" content="2019-09-03 13:35:07 +0000">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- meta "search-domain" used for google site search function google_search() -->
    <meta name="search-domain" value="https://datacarpentry.org/image-processing">
    <link rel="stylesheet" type="text/css" href="./Contours – Image Processing with Python_files/bootstrap.css">
    <link rel="stylesheet" type="text/css" href="./Contours – Image Processing with Python_files/bootstrap-theme.css">
    <link rel="stylesheet" type="text/css" href="./Contours – Image Processing with Python_files/lesson.css">
    <link rel="stylesheet" type="text/css" href="./Contours – Image Processing with Python_files/syntax.css">

    



    <!-- Favicons for everyone -->
    <link rel="apple-touch-icon-precomposed" sizes="57x57" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon-precomposed" sizes="60x60" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon-precomposed" sizes="120x120" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon-precomposed" sizes="76x76" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="https://datacarpentry.org/image-processing/assets/favicons/dc/apple-touch-icon-152x152.png">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-196x196.png" sizes="196x196">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="https://datacarpentry.org/image-processing/assets/favicons/dc/favicon-128.png" sizes="128x128">
    <meta name="application-name" content="Data Carpentry - Image Processing with Python">
    <meta name="msapplication-TileColor" content="#FFFFFF">
    <meta name="msapplication-TileImage" content="../assets/favicons/dc/mstile-144x144.png">
    <meta name="msapplication-square70x70logo" content="../assets/favicons/dc/mstile-70x70.png">
    <meta name="msapplication-square150x150logo" content="../assets/favicons/dc/mstile-150x150.png">
    <meta name="msapplication-wide310x150logo" content="../assets/favicons/dc/mstile-310x150.png">
    <meta name="msapplication-square310x310logo" content="../assets/favicons/dc/mstile-310x310.png">


    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->

  <title>
  Contours – Image Processing with Python
  </title>  

  </head>
  <body>

    



    <div class="container">
      






<nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      
      
      <a href="http://datacarpentry.org/" class="pull-left">
        <img class="navbar-logo" src="./Contours – Image Processing with Python_files/dc-icon-black.svg" alt="Data Carpentry logo">
      </a>
      

      
      <a class="navbar-brand" href="https://datacarpentry.org/image-processing/">Home</a>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

	
        <li><a href="https://datacarpentry.org/image-processing/CODE_OF_CONDUCT.html">Code of Conduct</a></li>

        
	
        <li><a href="https://datacarpentry.org/image-processing/setup/">Setup</a></li>

        
        <li class="dropdown">
          <a href="https://datacarpentry.org/image-processing/" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Episodes <span class="caret"></span></a>
          <ul class="dropdown-menu">
            
            <li><a href="https://datacarpentry.org/image-processing/01-introduction/">Introduction</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/02-image-basics/">Image Basics</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/03-opencv-images/">OpenCV Images</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/04-drawing-bitwise/">Drawing and Bitwise Operations</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/05-creating-histograms/">Creating Histograms</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/06-blurring/">Blurring images</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/07-thresholding/">Thresholding</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/08-edge-detection/">Edge Detection</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/09-contours/">Contours</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/10-challenges/">Challenges</a></li>
            
	    <li role="separator" class="divider"></li>
            <li><a href="https://datacarpentry.org/image-processing/aio/index.html">All in one page (Beta)</a></li>
          </ul>
        </li>
	

	
	
        <li class="dropdown">
          <a href="https://datacarpentry.org/image-processing/" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Extras <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="https://datacarpentry.org/image-processing/reference/">Reference</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/about/">About</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/discuss/">Discussion</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/figures/">Figures</a></li>
            
            <li><a href="https://datacarpentry.org/image-processing/guide/">Instructor Notes</a></li>
            
          </ul>
        </li>
	

	
        <li><a href="https://datacarpentry.org/image-processing/LICENSE.html">License</a></li>
	
	<li><a href="https://github.com/datacarpentry/image-processing/edit/gh-pages/_episodes/09-contours.md" data-checker-ignore="">Improve this page <span class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a></li>
	
      </ul>
      <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form>
    </div>
  </div>
</nav>

















<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="https://datacarpentry.org/image-processing/08-edge-detection/"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
    <h3 class="maintitle"><a href="https://datacarpentry.org/image-processing/">Image Processing with Python</a></h3>
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="https://datacarpentry.org/image-processing/10-challenges/"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>

<article>
<div class="row">
  <div class="col-md-1">
  </div>
  <div class="col-md-10">
    <h1 class="maintitle">Contours</h1>
  </div>
  <div class="col-md-1">
  </div>
</div>


<blockquote class="objectives">
  <h2>Overview</h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 90 min
      <br>
      <strong>Exercises:</strong> 70 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can we find contours in an image, and what can we do with contours?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Explain the difference between edges and contours in an image.</p>
</li>
	
	<li><p>Use the <code class="highlighter-rouge">cv2.findContours()</code> function to find the contours in an image.</p>
</li>
	
	<li><p>Describe the difference between finding contours with <code class="highlighter-rouge">cv2.RETR_EXTERNAL</code> and <code class="highlighter-rouge">cv2.RETR_TREE</code> when finding contours.</p>
</li>
	
	<li><p>Describe the hierarchical relationship between the contours of an image.</p>
</li>
	
	<li><p>Use the <code class="highlighter-rouge">cv2.boundingRect()</code> function to find the bounding boxes of the contours in an image.</p>
</li>
	
	<li><p>Use contours and bounding boxes to create a mask to select objects from an image.</p>
</li>
	
	<li><p>Use moments to find the centroid of contours.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<p>In this episode, we will learn how to use OpenCV functions to find the 
<em>contours</em> of the objects in an image. A contour is a closed curve of points
or line segments, representing the boundaries of an object in an image. In 
other words, contours represent the shapes of objects found in an image. If 
internal detail is visible in an image, the object may produce several 
associated contours, which are returned in a hierarchical data structure. Once 
we find the contours of the objects in an image, we can do things like 
determine the number of objects in an image, classify the shapes of the 
objects, or measure the size of the objects. The input to the contour-finding 
process is a binary image, which we will produce by first applying thresholding 
and / or edge detection. In the binary image, the objects we wish to detect 
should be white, while the background of the image should be black.</p>

<h2 id="edges-versus-contours">Edges versus contours</h2>

<p>Based on the introduction above, it is not immediately apparent what the 
difference is between finding the edges in an image and finding the 
contours in an image. A superficial examination of the output of the two 
processes does not help matters. Consider the colored shapes image from the
<a href="https://datacarpentry.org/image-processing/07-thresholding">Thresholding</a> episode:</p>

<p><img src="./Contours – Image Processing with Python_files/06-junk-before.jpg" alt="Colored shapes"></p>

<p>Now, consider the output of edge detection and contour detection for that 
image:</p>

<p><img src="./Contours – Image Processing with Python_files/08-edge-versus-contour.jpg" alt="Edges versus contours"></p>

<p>There certainly does not seem to be much difference between the two resulting
images! But, underneath the surface, the difference between edges and contours 
is significant. When we perform edge detection, we find the points where the 
intensity of colors changes significantly, and turn those pixels on, while
turning the rest of the pixels off. The edge pixels are in an image, and there
is no particular requirement that the pixels representing an edge are all
contiguous.</p>

<p>Contours, on the other hand, are not necessarily part of an image, unless we 
choose to draw them (as we did for the contour image above). Rather, contours
are <em>abstract</em> collections of points and / or line segments corresponding to 
the shapes of the objects in the image. Thus, they can be manipulated by our 
programs; we can count the number of contours, use them to categorize the 
shapes in the object, use them to crop objects from an image, and more. So, 
let us see how to find contours in an image, and use the contours to determine 
the number of objects in the image.</p>

<h2 id="using-contours-to-count-objects">Using contours to count objects</h2>

<p>Consider this image of several six-sided dice on a black background.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice.jpg" alt="Dice"></p>

<p>Suppose we want to automatically count the number of dice in the image. We can
use contours to do that. We find contours with the <code class="highlighter-rouge">cv2.findContours()</code> function,
and then easily examine the results to count the number of objects. Our 
strategy will be this:</p>

<ol>
  <li>
    <p>Read the input image, convert it to grayscale, and blur it slightly.</p>
  </li>
  <li>
    <p>Use simple fixed-level thresholding to convert the grayscale image to a 
binary image.</p>
  </li>
  <li>
    <p>Use the <code class="highlighter-rouge">cv2.findContours()</code> function to find contours corresponding to the 
outlines of the dice.</p>
  </li>
  <li>
    <p>Print information on how many contours – and thus how many objects – were
found in the image.</p>
  </li>
  <li>
    <p>For illustrative purposes, draw the contours in the original image so we can
visualize the results.</p>
  </li>
</ol>

<p>Before we examine a Python program to implement this strategy, let us first 
look at the grayscale histogram for the dice image, so we can find a threshold
value that will effectively convert the image to binary.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-histogram.png" alt="Dice grayscale histogram"></p>

<p>Since finding contours works on white objects set against a black background, 
in our thresholding we want to turn off the pixels in the background, while 
turning on the pixels associated with the face of the dice. Based on the 
histogram, a threshold value of 200 seems likely to do that.</p>

<p>Here is a Python program to count the number of dice in the preceding image
via contours. We start with familiar steps: we save the command-line arguments for the 
filename and threshold value, read the original image, convert it to 
grayscale, blur it, and convert to a binary image via <code class="highlighter-rouge">cv2.threshsold()</code>, with
the resulting image save in the <code class="highlighter-rouge">binary</code> variable.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
 * Python program to use contours to count the objects in an image.
 *
 * usage: python Contours.py &lt;filename&gt; &lt;threshold&gt;
'''
import cv2, sys

# read command-line arguments
filename = sys.argv[1]
t = int(sys.argv[2])

# read original image
image = cv2.imread(filename = filename)

# create binary image
gray = cv2.cvtColor(src = image, code = cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(src = gray, 
    ksize = (5, 5), 
    sigmaX = 0)
(t, binary) = cv2.threshold(src = blur,
    thresh = t, 
    maxval = 255, 
    type = cv2.THRESH_BINARY)
</code></pre></div></div>

<p>We do not display the binary
image in the program, but if we did, it would look like this, assuming a 
threshold value of 200:</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-binary.jpg" alt="Dice binary image"></p>

<p>Now, we find the contours, based on the binary image of the dice. The way we 
are using <code class="highlighter-rouge">cv2.findContours()</code> function takes three parameters, and it returns 
three values:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(_, contours, _) = cv2.findContours(image = binary, 
    mode = cv2.RETR_EXTERNAL,
    method = cv2.CHAIN_APPROX_SIMPLE)
</code></pre></div></div>

<p>The first parameter to the function is the image to find contours in. 
Remember, this image should be binary, with the objects you wish to find 
contours for in white, against a black background. Second, we pass in a 
constant indicating what kind of contours we are interested in. Since we are
interested in counting the objects in this image, we only care about the 
contours around the outermost edges of the objects, and so we pass in the 
<code class="highlighter-rouge">cv2.RETR_EXTERNAL</code> parameter. If we wished to have more information – say, 
contours associated with the pips on the faces of the dice – then we could use
another parameter, such as <code class="highlighter-rouge">cv2.RETR_TREE</code> or <code class="highlighter-rouge">cv2.RETR_CCOMP</code>. See the OpenCV 
documentation <a href="http://docs.opencv.org/trunk/d3/dc0/group__imgproc__shape.html#ga819779b9857cc2f8601e6526a3a5bc71">here</a>
for more information. The last parameter tells the function if it 
should simplify the contours or not. We pass in <code class="highlighter-rouge">cv2.CHAIN_APPROX_SIMPLE</code>, 
which tells the function to simplify by using line segments when it can, rather
that including all the points on what would be a straight edge. Using this
parameter saves memory and computation time in our program.</p>

<p>The <code class="highlighter-rouge">cv2.findContours()</code> function returns three values, as a tuple; in this case,
we are choosing to ignore the first and third return value. The first value
is an intermediate image that is produced during the contour-finding process. 
We are not interested in that image in this application, so we effectively
discard that image by placing the underscore (<code class="highlighter-rouge">_</code>) in the place of the first 
return value. The second return value is a list of NumPy arrays. Each array 
holds the points for one contour in the image. So, if we have executed our 
strategy correctly, the number of contours – the length of the <code class="highlighter-rouge">contours</code> list
– will be the number of objects in the image. The final return value is a 
NumPy array that contains hierarchy information about the contours. This is not
useful to us in our object-counting program, so we also choose to discard that
return value with the <code class="highlighter-rouge">_</code>.</p>

<p>After finding the contours of the image, we print information about them out to
the terminal, so that we can see the number of objects detected in the image. 
The code that does the printing looks like this:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print("Found %d objects." % len(contours))
for (i, c) in enumerate(contours):
    print("\tSize of contour %d: %d" % (i, len(c)))
</code></pre></div></div>

<p>First, we print the number of objects found, which is the length of the 
<code class="highlighter-rouge">contours</code> list. This usage of the <code class="highlighter-rouge">print()</code> function uses a 
<em>format specifier</em>, <code class="highlighter-rouge">%d</code>. A format specifier is a placeholder in a string, in
this case standing in for an integer. After the string, we place the value(s) 
to substitute for the placeholder(s), after the <code class="highlighter-rouge">%</code> character. You can find
more information regarding formatting strings 
<a href="https://docs.python.org/3.4/library/string.html">here</a>.</p>

<p>Then, we iterate through the contours list to show how many points are in each
contour. The <code class="highlighter-rouge">enumerate(contours)</code> function call goes through the list, as we 
normally do in a <code class="highlighter-rouge">for</code> loop, but we also associate an integer, <code class="highlighter-rouge">i</code>, with each
element of the list. This lets us print out the number of the contour, starting
with zero, and then the size of each contour with the for loop. The output of 
this loop, assuming we used the dice image above and a threshold value of 200, 
is:</p>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found 7 objects.
	Size of contour 0: 423
	Size of contour 1: 476
	Size of contour 2: 497
	Size of contour 3: 456
	Size of contour 4: 327
	Size of contour 5: 622
	Size of contour 6: 570
</code></pre></div></div>

<p>Finally, we draw the contour points on the original image, with the</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cv2.drawContours(image = image, 
    contours = contours, 
    contourIdx = -1, 
    color = (0, 0, 255), 
    thickness = 5)
</code></pre></div></div>

<p>function call. The first parameter is the image we are going to draw the contours
on. Then, we pass in the list of contours to draw. The third parameter tells us
where to start when we draw the contours; -1 means to draw them all. If we 
specified 2 here, only the third contour would be drawn. The fourth parameter
is the color to use when drawing the contours. Finally, we specify the 
thickness of the contour points to draw. Here we are drawing the contours in 
red, with a thickness of 5, so they will be very visible on the image.</p>

<p>After the contours are drawn on the image, we display the image in a window. 
Here are the seven contours detected by the program.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-contours.jpg" alt="Dice image contours"></p>

<h2 id="understanding-contour-hierarchies">Understanding contour hierarchies</h2>

<p>Now let us turn our attention to one of the two return values from 
<code class="highlighter-rouge">cv2.findContours()</code> that we ignored in the previous section, namely, the 
<em>hierarchies</em>. Suppose we change the <code class="highlighter-rouge">cv2.RETR_EXTERNAL</code> parameter in our 
contours function call to <code class="highlighter-rouge">cv2.RETR_TREE</code> instead, so that we will receive all of
the contours in the image, instead of just the outermost contours for each 
image. If we draw the resulting contours and color things appropriately, we
will see something like this:</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-all-contours.jpg" alt="All dice image contours"></p>

<p>When we use the <code class="highlighter-rouge">cv2.RETR_TREE</code> parameter, the contours are arranged in a 
hierarchy, with the outermost contours for each object at the top. Moving down
the hierarchy, each new level of contours represents the next innermost contour
for each object. In the image above, the contours in the image are colored to 
represent the hierarchical structure of the returned contours data. The 
outermost contours are red, and they are at the top of the hierarchy. The next 
innermost contours – the dice pips, in this case – are green. The innermost 
contours, representing some lost paint in one of the pips in the central die, 
are blue.</p>

<p>We can get that information about the contour hierarchies via the third return
value from the <code class="highlighter-rouge">cv2.findContours()</code> function call. Suppose we call the function 
like this:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(_, contours, hierarchy) = cv2.findContours(image = binary, 
    mode = cv2.RETR_TREE,
    method = cv2.CHAIN_APPROX_SIMPLE)
</code></pre></div></div>

<p>The third return value, saved in the <code class="highlighter-rouge">hierarchy</code> variable in this code, is a 
three-dimensional NumPy array, with one row, 36 columns, and a “depth” of 4.
The 36 columns correspond to the contours found by the function; note that there
are 36 contours now, rather than seven. This is because the <code class="highlighter-rouge">cv2.RETR_TREE</code>
parameter causes the function to find the internal contours as well as the 
outermost contours for each object. Column zero corresponds to the first 
contour, column one the second, and so on.</p>

<p>Each of the columns has a four-element array of integers, representing indices 
of other contours, according to this scheme:</p>

<p>[<em>next</em>, <em>previous</em>, <em>first child</em>, <em>parent</em>]</p>

<p>The <em>next</em> index refers to the next contour in this contour’s hierarchy level,
while the <em>previous</em> index refers to the previous contour in this contour’s 
hierarchy level. The <em>first child</em> index refers to the first contour that is 
contained inside this contour. The <em>parent</em> index refers to the contour 
containing this contour. In all cases, an value of -1 indicates that there is 
no <em>next</em>, <em>previous</em>, <em>first child</em>, or <em>parent</em> contour, as appropriate. 
For a more concrete example, here are the <code class="highlighter-rouge">hierarchy</code> values for the dice 
image. The values are in square brackets, and the indices of the contours 
precede each entry.</p>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0:	[ 6 -1  1 -1]	18:	[19 -1 -1 17]
1:	[ 2 -1 -1  0]	19:	[20 18 -1 17]
2:	[ 3  1 -1  0]	20:	[21 19 -1 17]
3:	[ 4  2 -1  0]	21:	[22 20 -1 17]
4:	[ 5  3 -1  0]	22:	[-1 21 -1 17]
5:	[-1  4 -1  0]	23:	[27 17 24 -1]
6:	[11  0  7 -1]	24:	[25 -1 -1 23]
7:	[ 8 -1 -1  6]	25:	[26 24 -1 23]
8:	[ 9  7 -1  6]	26:	[-1 25 -1 23]
9:	[10  8 -1  6]	27:	[32 23 28 -1]
10:	[-1  9 -1  6]	28:	[29 -1 -1 27]
11:	[17  6 12 -1]	29:	[30 28 -1 27]
12:	[15 -1 13 11]	30:	[31 29 -1 27]
13:	[14 -1 -1 12]	31:	[-1 30 -1 27]
14:	[-1 13 -1 12]	32:	[-1 27 33 -1]
15:	[16 12 -1 11]	33:	[34 -1 -1 32]
16:	[-1 15 -1 11]	34:	[35 33 -1 32]
17:	[23 11 18 -1]	35:	[-1 34 -1 32]
</code></pre></div></div>

<p>The entry for the first contour is [6, -1, 1, -1]. This represents the first of
the outermost contours; note that there is no particular order for the 
contours, e.g., they are not stored left to right by default. The entry tells 
us that the next dice outline is the contour with index six, that there is no
previous contour in the list, that the first contour inside this one has index
one, and that there is no parent for this contour (no contour containing this
one). We can visualize the information in the <code class="highlighter-rouge">hierarchy</code> array as seven trees,
one for each of the dice in the images.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-hierarchy.png" alt="Dice contour hierarchies"></p>

<p>The seven outermost contours all those that have no parent, i.e., those with
an value of -1 in the fourth field of their <code class="highlighter-rouge">hierarchy</code> entry. Each of the 
child nodes beneath one of the “roots” represents a contour inside the 
outermost contour. Note how contours 13 and 14 are beneath contour 12 in the
diagram. Those two contours represent the blue spots in the contour hierarchy
image above.</p>

<p>Once we understand how contours are arranged into a hierarchy, we can perform
more sophisticated tasks, such as counting the number of contours within a 
shape in addition to the number of objects in an image.</p>

<blockquote class="challenge">
  <h2 id="counting-dice-pips-45-minutes">Counting dice pips (45 minutes)</h2>

  <p>Now let us see how we can count the total number of pips showing on the faces
of the dice in the preceding image. Navigate to the 
<strong>Desktop/workshops/image-processing/09-contours</strong> directory, and edit the 
<strong>Gladys.py</strong> program. You will see that the program is very much like the 
one we used to count the number of dice, except that it finds contours with
the <code class="highlighter-rouge">cv2.RETR_TREE</code> parameter instead of <code class="highlighter-rouge">cv2.RETR_EXTERNAL</code>. Edit the 
program, following the comments in the code, to print out the total dice
roll in the <strong>dice.jpg</strong> image.</p>

  <p><em>Hint: First, create a list of the indices of the outermost contours. Then,
make a list of contour indices that have parents in the first list. The 
length of the second list should be the pip count.</em></p>

  <blockquote class="solution">
    <h2 id="solution">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span></h2>

    <p style="display: none;">Here is a the finished version of <strong>Gladys.py</strong>.</p>

    <div class="python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>'''
 * Python program to use contours to count the pips on the dice faces.
 *
 * usage: python Gladys.py &lt;filename&gt; &lt;threshold&gt;
'''
import cv2, sys

# read command-line arguments
filename = sys.argv[1]
t = int(sys.argv[2])

# read original image
image = cv2.imread(filename = filename)

# create binary image
gray = cv2.cvtColor(src = image, code = cv2.COLOR_BGR2GRAY)

blur = cv2.GaussianBlur(src = gray, 
    ksize = (5, 5), 
    sigmaX = 0)

(t, binary) = cv2.threshold(src = blur, 
    thresh = t, 
    maxval = 255, 
    type = cv2.THRESH_BINARY)

# find contours
(_, contours, hierarchy) = cv2.findContours(image = binary, 
    mode = cv2.RETR_TREE, 
    method = cv2.CHAIN_APPROX_SIMPLE)

# Count the number of pips on the dice faces.
# Iterate through hierarchy[0], first to find the indices of dice
# contours, then again to find pip contours.
# WRITE YOUR CODE HERE

dice = []   # list of dice contours
pips = []   # list of pip contours

# find dice contours
for (i, c) in enumerate(hierarchy[0]):
    if c[3] == -1:
        dice.append(i)
    
# find pip contours
for (i, c) in enumerate(hierarchy[0]):
    if c[3] in dice:
        pips.append(i)
        
print("Total die roll:", len(pips))
</code></pre></div>    </div>

    <p style="display: none;">When executed on the <strong>dice.jpg</strong> image, with a threshold value of 200, the
program produces this output:</p>

    <div class="output highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>Total die roll: 27
</code></pre></div>    </div>

    <p style="display: none;">But wait! The total should be 28, should it not? What went wrong? The 
answer lies in the pip contours for the die showing 6. That die happens to
be associated with the contour with index zero, which only has five 
children in the hierarchy tree diagram above. If we draw only the first 
contour in the first die, we see this:</p>

    <p style="display: none;"><img src="./Contours – Image Processing with Python_files/08-dice-double-pip.jpg" alt="Double pip contour"></p>

    <p style="display: none;">The single contour – the one with index one – actually covers two pips!
That explains why our pip count is off by one. We might have been able to
prevent that problem when taking the image, when blurring the image, or
when making the binary image with thresholding. Care must be taken when 
working with image processing, especially in scientific applications, to
make sure that the results reported by the program are reliable.</p>
  </blockquote>
</blockquote>

<h2 id="bounding-boxes-and-cropping">Bounding boxes and cropping</h2>

<p>Aside from counting the number of objects in an image, one of the things we can
do with contours is find their <em>bounding boxes</em>. A bounding box is the smallest
rectangle that completely contains a given contour. For example, for the dice 
image we used in the previous section, here are the bounding boxes:</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-boxes.jpg" alt="Bounding boxes"></p>

<p>As before the contours for the objects are drawn in red, while the bounding 
boxes for the contours are drawn in green. These rectangles were found with the
<code class="highlighter-rouge">cv2.boundingRect()</code> function call, which takes a contour as its parameter. You 
can see that the rectangles are oriented so that the rectangle sides are 
perfectly vertical or horizontal. So, if the objects in the image are rotated
significantly from that perfect orientation, the bounding boxes will not have 
the best possible fit. It is possible to find bounding boxes (or circles, or 
ellipses) with a better fit by using other OpenCV methods.</p>

<p>One application for bounding boxes is to use them to crop objects from an 
image. So that we can use the simple <code class="highlighter-rouge">cv2.boundingRect()</code> function to find our
bounding boxes, let us use another dice image; this one will have dice that are
more carefully aligned.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-grid.jpg" alt="More dice"></p>

<p>Before we turn to seeing how to find the bounding boxes, and how to use them 
for cropping, here is what the bounding boxes look like for the new set of 
dice. The contours are not drawn on this image.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-grid-boxes.jpg" alt="Bounding boxes for the new image"></p>

<p>Our goal here is to use the bounding boxes to select only the dice faces from
the image. So, we want to do something akin to thresholding, but instead of 
producing a binary image, we wish to have full-color versions of the dice 
faces at the end of the process. Our strategy will be similar to the one we 
used to find the contours:</p>

<ol>
  <li>Read the input image, convert it to grayscale, and blur it slightly.</li>
  <li>Use simple binary thresholding to convert the grayscale image to a binary
image.</li>
  <li>Use <code class="highlighter-rouge">cv2.findContours()</code> to find the contours corresponding to the outlines
of the faces of the dice.</li>
  <li>Create a blank, black mask image the same size as the original.</li>
  <li>For each contour found, do the following:
    <ul>
      <li>Use <code class="highlighter-rouge">cv2.boundingRect()</code> to find the bounding box of the contour</li>
      <li>Draw a filled, white rectangle corresponding to the bounding box on the 
mask image</li>
    </ul>
  </li>
  <li>Use a bitwise and operation on the original image and the mask, producing 
the final image.</li>
</ol>

<p>Here is a Python program that implements this strategy. Everything up through 
finding the contours is the same as the previous program,
so we will not go through that part of the code again.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
 * Python program to use contours to crop the objects in an image.
 *
 * usage: python ContourCrop.py &lt;filename&gt; &lt;threshold&gt;
'''
import cv2, sys, numpy as np

# read command-line arguments
filename = sys.argv[1]
t = int(sys.argv[2])

# read original image
image = cv2.imread(filename = filename)

# create binary image
gray = cv2.cvtColor(src = image, code = cv2.COLOR_BGR2GRAY)

blur = cv2.GaussianBlur(src = gray, 
    ksize = (5, 5), 
    sigmaX = 0)

(t, binary) = cv2.threshold(src = blur, 
    thresh = t, 
    maxval = 255, 
    type = cv2.THRESH_BINARY)

# find contours
(_, contours, _) = cv2.findContours(image = binary, 
    mode = cv2.RETR_EXTERNAL, 
    method = cv2.CHAIN_APPROX_SIMPLE)
</code></pre></div></div>

<p>Once we have found the 
contours, we create a mask using the <code class="highlighter-rouge">np.zeros()</code> function, as we did in the 
<a href="https://datacarpentry.org/image-processing/04-drawing-bitwise/">Drawing and Bitwise Operations</a>
episode.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># create all-black mask image
mask = np.zeros(shape = image.shape, dtype = "uint8")
</code></pre></div></div>

<p>Then, we use a <code class="highlighter-rouge">for</code> loop to iterate through the list of contours,
finding the bounding box and drawing the box on the mask image:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for c in contours:
    (x, y, w, h) = cv2.boundingRect(c)

    cv2.rectangle(img = mask, 
        pt1 = (x, y), 
        pt2 = (x + w, y + h), 
        color = (255, 255, 255), 
        thickness = -1)
</code></pre></div></div>

<p>Remember that contours are stored in a list, so when we use the <code class="highlighter-rouge">for</code> loop to
iterate through the list, each time through the loop works with an individual 
contour, stored in the variable <code class="highlighter-rouge">c</code>.</p>

<p>Inside the loop, we pass the current contour <code class="highlighter-rouge">c</code> to the <code class="highlighter-rouge">cv2.boundingRect()</code> 
function, and we receive a tuple of four values as in return: the x and y 
coordinates of the upper-left corner of the bounding box, and the width and 
height of the box. We store these in the <code class="highlighter-rouge">(x, y, w, h)</code> tuple.</p>

<p>Then, we draw a solid white rectangle on the mask image, corresponding to the 
bounding box, with the <code class="highlighter-rouge">cv2.rectangle()</code> function call. It has been a while
since we have used this function, so let us review the parameters we pass in.
First, <code class="highlighter-rouge">mask</code> is the image we will draw the rectangles on. Next is a tuple with
the coordinates of the upper-left corner of the rectangle, <code class="highlighter-rouge">(x, y)</code>. Next, we
provide a tuple with the coordinates of the lower-right corner of the 
rectangle, <code class="highlighter-rouge">(x + w, y + h)</code>; note how we add the width and height of the 
rectangle to the previous coordinates. Then, we pass in the color for the 
rectangle, white in this case. Finally, we pass in <code class="highlighter-rouge">-1</code>, which tells the function
to draw a filled rectangle.</p>

<p>The program does not display the finished mask image, but if we were to examine
it, it would look like this (assuming the second dice image and a threshold 
value of 200):</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-grid-mask.jpg" alt="Dice mask"></p>

<p>After the <code class="highlighter-rouge">for</code> loop, we use the <code class="highlighter-rouge">cv2.bitwise_and()</code> function to apply our mask 
to the original image.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># apply mask to the original image
image = cv2.bitwise_and(src1 = image, src2 = mask)
</code></pre></div></div>

<p>The effect is to select only the dice faces, while 
making everything else in the image black:</p>

<p><img src="./Contours – Image Processing with Python_files/08-dice-cropped.jpg" alt="Cropped dice"></p>

<blockquote class="challenge">
  <h2 id="extracting-subimages-25-minutes">Extracting subimages (25 minutes)</h2>

  <p>Now, what if we wished to extract the eight dice faces from the preceding 
image into eight separate images? That is your challenge here. Navigate to the
<strong>Desktop/workshops/image-processing/09-contours</strong> directory, and edit the 
<strong>ExtractSubimages.py</strong> program. The program is much like the one we just 
used. There are two places where you should write code in the <code class="highlighter-rouge">for</code> loop to 
create eight different subimages, each containing one of the dice faces from
the <strong>dice-grid.jpg</strong> image. Once you have made your edits, run the program
like this:</p>

  <div class="bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python ExtractSubimages.py dice-grid.jpg 200
</code></pre></div>  </div>

  <blockquote class="solution">
    <h2 id="solution-1">Solution<span class="fold-unfold glyphicon glyphicon-collapse-down"></span></h2>

    <p style="display: none;">Here is the completed version of the program.</p>

    <div class="python highlighter-rouge" style="display: none;"><div class="highlight"><pre class="highlight"><code>'''
 * Python program to use contours to extract the objects in an image.
'''
import cv2, sys

# read command-line arguments
filename = sys.argv[1]
t = int(sys.argv[2])

# read original image
image = cv2.imread(filename = filename)

# create binary image
gray = cv2.cvtColor(src = image, code = cv2.COLOR_BGR2GRAY)

blur = cv2.GaussianBlur(src = gray, 
    ksize = (5, 5), 
    sigmaX = 0)

(t, binary) = cv2.threshold(src = blur, 
    thresh = t, 
    maxval = 255, 
    type = cv2.THRESH_BINARY)

# find contours
(_, contours, _) = cv2.findContours(image = binary, 
    mode = cv2.RETR_EXTERNAL, 
    method = cv2.CHAIN_APPROX_SIMPLE)

# use the contours to extract each image, into a new sub-image
for (i, c) in enumerate(contours):
    (x, y, w, h) = cv2.boundingRect(c)
    # WRITE YOUR CODE HERE!
    # use slicing and the (x, y, w, h) values of the bounding
    # box to create a subimage based on this contour
    subImg = image[y : y + h, x : x + w, :]
    
    # WRITE YOUR CODE HERE!
    # save the subimage as sub-x.jpg, where x is the number
    # of this contour. HINT: try "sub-{0}".format(i) to 
    # create the filename
    cv2.imwrite(filename = "sub-{}.jpg".format(i), img = subImg)
</code></pre></div>    </div>

    <p style="display: none;">The program produces eight subimages, shown here. Note that there is no
particular order to the contours found by the <code class="highlighter-rouge">cv2.findContours()</code> function!</p>

    <p style="display: none;"><img src="./Contours – Image Processing with Python_files/08-dice-individual.jpg" alt="Individual dice faces"></p>

  </blockquote>
</blockquote>

<h2 id="getting-more-information-from-contours-moments">Getting more information from contours: moments</h2>

<p>We can get more information from contours, beyond shape, hierarchy, and 
bounding boxes. Once we have the contours, we can use them to get the <em>moments</em>
for the corresponding objects in the image. The moments of an object are 
weighted averages of pixel intensities, or functions upon those averages, and
the precise details of the mathematics involved is fairly complicated. Luckily,
we can easily use moments to determine things like the center of an object, the
area inside a contour, and more, without worrying about the mathematics behind
the scenes.</p>

<p>Consider this image of colored paper-punch circles on a white background, and 
suppose we want to write a program to count the number of yellow dots in the 
image.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dots.jpg" alt="Paper punch dots"></p>

<p>The grayscale histogram for this image shows that there is a large spike, 
representing the white background, just above 200.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dots-histogram.png" alt="Dots grayscale histogram"></p>

<p>Our strategy for counting the number of yellow dots is as follows:</p>

<ol>
  <li>Read the image, make a grayscale version, blur it, and apply thresholding
to create a binary image.</li>
  <li>Use the binary image to find the contours in the image.</li>
  <li>Determine the average size of the contours. This will be used to ignore
small contours that represent noise rather than dots.</li>
  <li>Iterate through the contours, and for all contours that are big enough:
    <ul>
      <li>Using the moments of the contour, find the contour centroid.</li>
      <li>Determine the average color around the contour centroid.</li>
      <li>Find the Euclidean distance between the average color and three reference
colors: yellow, blue, and green.</li>
      <li>If the average color is closest the the yellow reference color, add one 
to the count of yellow dots</li>
    </ul>
  </li>
  <li>Output the number of yellow dots.</li>
</ol>

<p>Our need for step three in the strategy is easy to see, if we simply look at 
all the contours found by the <code class="highlighter-rouge">cv2.findContours()</code> function. The contours are
drawn in red in this image.</p>

<p><img src="./Contours – Image Processing with Python_files/08-dots-all-contours.jpg" alt="All contours in the dots image"></p>

<p>Notice that quite a few contours have been found that do not correspond to any
of the dots in the image. These are associated either with imperfections in the
white background or with noise in the image, and they are much smaller than the
contours associated with the dots. So, we need to ignore these “noisy” contours
when we try to count colored dots. If we determine the average size of the 
contours, and pay attention only to those that are larger than, say, one-half
of the average, we will skip the contours we are not interested in.</p>

<p>Here is a Python program implementing our strategy to count the yellow dots in
the image. At the top of the program we import the libraries we will need. This is the
first time we have included the <code class="highlighter-rouge">math</code> library, which we will require for the
<code class="highlighter-rouge">sqrt()</code> function.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
 * Python program to count the number of yellow dots in an image.
 *
 * usage: python CountYellow.py &lt;filename&gt; &lt;kernel-size&gt; &lt;threshold&gt;
'''
import cv2, sys, math, numpy as np
</code></pre></div></div>

<p>After the imports, we define a function to compute the Euclidean distance 
between two RGB colors.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
 * Compute distance between two colors, as a 3D Euclidean distance.
'''
def colorDistance(kCol, uCol):
    # compute sum of square of differences between each channel 
    d = (kCol[0] - uCol[0])**2 + (kCol[1] - uCol[1])**2 + \
        (kCol[2] - uCol[2])**2
        
    # square root of sum is the Euclidean distance between the
    # two colors
    return math.sqrt(d)
</code></pre></div></div>

<p>We will use this function to tell whether the average
color for a dot is closest to yellow, blue, or green. The function simply 
computes the geometric distance between two three-dimensional points. <code class="highlighter-rouge">kCol</code>
is the known color parameter and <code class="highlighter-rouge">uCol</code> is the unknown color parameter, so the
distance between these two colors is given by:</p>

<p><img src="./Contours – Image Processing with Python_files/08-euclidean-distance.png" alt="Euclidean distance formula"></p>

<p>We choose to write this code as a function because we will need to do the 
difference calculation three times for every contour. So, rather than copy and
paste the code three times, we encapsulate it in a function. That is a good 
rule of thumb to follow: If you need top copy and paste code to use it more 
than once, put the code in a function.</p>

<p>In the main program, we save the command-line arguments, read the image, and 
then create a binary version through the now-familiar 
grayscale-blur-threshold procedure.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
 * Main program starts here.
'''

# read and save command-line arguments
filename = sys.argv[1]
k = int(sys.argv[2])
t = int(sys.argv[3])

# read image, convert to grayscale, blur, and threshold to
# make binary image
image = cv2.imread(filename = filename)

gray = cv2.cvtColor(src = image, code = cv2.COLOR_BGR2GRAY)

blur = cv2.GaussianBlur(src = gray, 
    ksize = (k, k), 
    sigmaX = 0)

(t, binary) = cv2.threshold(src = blur, 
    thresh = t, 
    maxval = 255, 
    type = cv2.THRESH_BINARY_INV)
</code></pre></div></div>

<p>Then, we find the contours in the image.
Note that we are not saving the hierarchy information here, as we will not 
require it to count the yellow dots.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># find contours
(_, contours, _) = cv2.findContours(image = binary, 
    mode = cv2.RETR_EXTERNAL, 
    method = cv2.CHAIN_APPROX_SIMPLE)
</code></pre></div></div>

<p>Our next block of code uses a <code class="highlighter-rouge">for</code> loop to determine the average size of the
contours in the image. Since we are interested in the mean <em>size</em> of the 
contours, not the mean of the <em>values</em> in <code class="highlighter-rouge">contours</code>, we cannot simply use the
NumPy <code class="highlighter-rouge">mean()</code> function.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># determine average length of contours
avg = 0
for c in contours:
    avg += len(c)
    
avg /= len(contours)
</code></pre></div></div>

<p>The code creates an <em>accumulator variable</em> named <code class="highlighter-rouge">avg</code>, with an initial value 
of zero. Then, in the <code class="highlighter-rouge">for</code> loop, we add the length of each contour to the 
<code class="highlighter-rouge">avg</code> accumulator. Finally, we divide the sum of the lengths by the number of
contours, yielding the average contour length.</p>

<p>Next, for convenience, we create tuples for each of our reference colors, 
<code class="highlighter-rouge">YELLOW</code>, <code class="highlighter-rouge">GREEN</code>, and <code class="highlighter-rouge">BLUE</code>. These will be passed in as the first parameter 
to the <code class="highlighter-rouge">colorDistance()</code> function when we are trying to classify the color for
a contour. We use all caps to indicate that these are intended to be constants,
i.e., that we should not change the values held in these variables.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># create reference colors
YELLOW = (0, 255, 255)
GREEN = (0, 255, 0)
BLUE = (255, 0, 0)
</code></pre></div></div>

<p>Before the next <code class="highlighter-rouge">for</code> loop that does the counting, we define another 
accumulator, <code class="highlighter-rouge">yellowCount</code>, to hold the running total of yellow dots.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># number of yellow dots
yellowCount = 0
</code></pre></div></div>

<p>The main <code class="highlighter-rouge">for</code> loop again iterates through the contours, and we only do the 
counting calculations for contours that are big enough to be associated with 
colored dots. We do this with the <code class="highlighter-rouge">if len(c) &gt; avg / 2:</code> control structure.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># for each contour...
for c in contours:
    
    # ... only work with contours associated with actual dots
    if len(c) &gt; avg / 2:
</code></pre></div></div>

<p>Inside the <code class="highlighter-rouge">if</code>, the first step is to use the moments of the current contour to
find its centroid, which is accomplished by this code:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        # find centroid of shape
        M = cv2.moments(array = c)
        cx = int(M['m10'] / M['m00'])
        cy = int(M['m01'] / M['m00'])
</code></pre></div></div>

<p>The <code class="highlighter-rouge">cv2.moments()</code> function call computes the moments for a contour. The return
value of the function call is a Python dictionary that contains the various 
moments for the contour. The <em>centroid</em>, or center point, for a contour can be
found by dividing specific moments, as shown in the code. We truncate the 
results of the divisions to integers, and save the coordinates of the center 
point in the <code class="highlighter-rouge">cx</code> and <code class="highlighter-rouge">cy</code> variables.</p>

<p>Now, we use array slicing to get the blue, green, and red color channels in a 
nine pixel kernel centered around the centroid of the image, with this code:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        # find average color for 9 pixel kernel around centroid
        b = img[cy - 4 : cy + 5, cx - 4 : cx + 5, 0]
        g = img[cy - 4 : cy + 5, cx - 4 : cx + 5, 1]
        r = img[cy - 4 : cy + 5, cx - 4 : cx + 5, 2]
</code></pre></div></div>

<p>Remember that the first dimension in a NumPy array holding an OpenCV image 
represents the y axis, the second dimension represents the x axis, and the 
third dimension represents the color channel, in BGR order. We get a nine pixel
kernel around the centroid by starting each slice at <code class="highlighter-rouge">cy - 4</code> or <code class="highlighter-rouge">cx - 4</code>, and
providing the index one beyond the ending coordinate with <code class="highlighter-rouge">cy + 5</code> or <code class="highlighter-rouge">cx + 5</code>.
We save the blue, green, and red color layers in the variables <code class="highlighter-rouge">b</code>, <code class="highlighter-rouge">g</code>, and 
<code class="highlighter-rouge">r</code>, respectively.</p>

<p>After that, we determine the average blue, green, and red 
color values using the <code class="highlighter-rouge">np.mean()</code> function, saving the results in <code class="highlighter-rouge">bAvg</code>, 
<code class="highlighter-rouge">gAvg</code>, and <code class="highlighter-rouge">rAvg</code>.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        bAvg = np.mean(b)
        gAvg = np.mean(g)
        rAvg = np.mean(r)
</code></pre></div></div>

<p>Now, we find the difference between the average color and the three reference
colors, and save the three results in a list, with this code:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        # find distances to known reference colors
        dist = []
        dist.append(colorDistance(YELLOW, (bAvg, gAvg, rAvg)))
        dist.append(colorDistance(BLUE, (bAvg, gAvg, rAvg)))
        dist.append(colorDistance(GREEN, (bAvg, gAvg, rAvg)))
</code></pre></div></div>

<p>After this block is complete, the <code class="highlighter-rouge">dist</code> list contains the distance between the
average color and the yellow, blue, and green reference colors, in that order. 
So, if the smallest distance in the list is in position zero of the list, we 
will classify this dot as being yellow. That is what is happening in the final
piece of code in the <code class="highlighter-rouge">if</code> statement within the <code class="highlighter-rouge">for</code> loop:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        # which one is closest?
        minDist = min(dist)
        # if it was yellow, count the shape
        if dist.index(minDist) == 0:
            yellowCount += 1
</code></pre></div></div>

<p>After the main loop is complete, the program reports the number of yellow dots
it counted.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print("Yellow dots:", yellowCount)
</code></pre></div></div>

<p>If executed on the <strong>dots.jpg</strong> image, with blur kernel size three
and threshold value 200, the program reports the correct number of yellow dots
in the image:</p>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Yellow dots: 24
</code></pre></div></div>

<h2 id="measuring-size-based-on-a-reference-object">Measuring size based on a reference object</h2>

<p>We can also use contours to automatically determine the size of objects in the
image, based on a <em>reference object</em> we intentionally place into the image. 
For example, consider this image of a leaf:</p>

<p><img src="./Contours – Image Processing with Python_files/08-leaf.jpg" alt="Leaf with reference object"></p>

<p>This image was created with a flatbed scanner. The background was a plain white
sheet of paper with a one inch black square situated in the upper left. The 
leaf was placed in front of the paper, the whole collection was placed on the 
scanner, and the image was captured. Since we know the size of the reference 
square, we can write a program to find the leaf and automatically determine
its size. Our plan will be:</p>

<ol>
  <li>Load the image as grayscale, blur it, threshold it, and find the contours</li>
  <li>Find the contour corresponding to the reference square, and measure the 
number of pixels in the width and height of the square’s sides</li>
  <li>Find the largest contour (which should be the leaf), and measure the 
number of pixels in its bounding rectangle sizes</li>
  <li>Calculate the width and height of the leaf</li>
</ol>

<p>Here is a Python program to perform these tasks. Everything up through finding 
the contours should be familiar by now.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
 * Python script to measure the size of an object, based on
 * the size of a reference object in the image.
 *
 * usage: python LeafSize.py &lt;filename&gt; &lt;threshold&gt;
'''
import cv2, sys

# read command-line arguments
filename = sys.argv[1]
t = int(sys.argv[2])

# read image as grayscale
image = cv2.imread(filename = filename, flags = cv2.IMREAD_GRAYSCALE)

# blur and threshold
blur = cv2.GaussianBlur(src = image,
    ksize = (5, 5),
    sigmaX = 0)

(t, binary) = cv2.threshold(src = blur,
    thresh = t,
    maxval = 255,
    type = cv2.THRESH_BINARY_INV)

# find contours
(_, contours, _) = cv2.findContours(image = binary, 
    mode = cv2.RETR_EXTERNAL,
    method = cv2.CHAIN_APPROX_SIMPLE)
</code></pre></div></div>

<p>In our iteration through the contours, we will ignore very small contours, which would
likely correspond to noise or irregularities in the paper background. To prepare for
that, we next calculate the average contour size. We also create variables to keep
track of the location of the largest contour, so we can measure the leaf at the end
of the program.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># determine average length of contours
avg = 0
for c in contours:
    avg += len(c)
    
avg /= len(contours)

# save index of largest contour
largestIdx = -1
largestSize = -1
</code></pre></div></div>

<p>Now we iterate through the contours. In our loop we do two things: find
the largest contour, and find the contour associated with the reference
square. The first <code class="highlighter-rouge">if</code> keeps track of the largest contour seen to date;
this will be the largest of all once the loop is finished.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># find size of the reference square
for i, c in enumerate(contours):
    # keep track of largest one
    if len(c) &gt; largestSize:
        largestSize = len(c)
        largestIdx = i
</code></pre></div></div>

<p>The next if statement makes sure we only look at contours that are large enough.
Here, we process contours only if they are at least one tenth the size of the
average.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    # now only look at the larger contours
    if len(c) &gt; avg / 10:
</code></pre></div></div>

<p>For the contours that are big enough, we compute a <em>polygon approximation</em> of
each contour. This simplifies contours into other shapes that are close to the
contour. Our goal is to find these polygon approximations, and look for the one
that has four vertices, for that will correspond to the reference square. This 
is done with the following code:</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        # get approximating polygon
        epsilon = 0.1 * cv2.arcLength(curve = c, closed = True)

        approx = cv2.approxPolyDP(curve = c,
            epsilon = epsilon,
            closed = True)
</code></pre></div></div>

<p>The <code class="highlighter-rouge">cv2.approxPolyDP()</code> function finds an approximating polygon for the 
contour passed in as the first parameter. The <code class="highlighter-rouge">epsilon</code> parameter controls 
how accurate the fit must be; it is the maximum distance allowed between the 
contour and the approximation. The third parameter indicates that we want a 
closed polygon as our approximation.</p>

<p>We arrive at our value of epsilon by calling the <code class="highlighter-rouge">cv2.arcLength()</code> function,
which computes the perimeter of a contour. We use 10% of the contour’s 
perimeter as our epsilon value here.</p>

<p>Next, the program looks at the number of vertices in the approximating polygon.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        # the one with four vertices should be the reference
        if len(approx) == 4:
            # save bounding rectangle info
            x, y, w, h = cv2.boundingRect(c)
</code></pre></div></div>

<p>If it is four, we can be confident that the contour is the square, instead of 
the length. Once we have the contour corresponding to the square, we save the
information pertinent to its bounding rectangle.</p>

<p>After the loop concludes, we use the bounding rectangle information to 
calculate scale variables, that represent the centimeters per pixel ratio in 
both the horizontal and vertical dimensions.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># calculate cm per pixels scale
scaleX = 2.54 / w
scaleY = 2.54 / h
</code></pre></div></div>

<p>Lastly, we get the bounding rectangle for the leaf, which is assumed to be the 
largest contour in the image.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code># get bounding box for the largest contour
x, y, w, h = cv2.boundingRect(contours[largestIdx])
</code></pre></div></div>

<p>Then, we are able to calculate the width and
height of the leaf.</p>

<div class="python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
# calculate height and width of the leaf
height = h * scaleY
width = w * scaleX

# print results
print('%0.2f cm wide x %0.2f cm tall' % (width, height))
</code></pre></div></div>

<p>When we run the program on the leaf image, with a threshold value of 200, we
receive this output:</p>

<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3.63 cm wide x 7.49 cm tall
</code></pre></div></div>


<blockquote class="keypoints">
  <h2>Key Points</h2>
  <ul>
    
    <li><p>Contours are closed curves of points or line segments, representing the boundaries of objects in an image.</p>
</li>
    
  </ul>
</blockquote>

</article>
















<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="https://datacarpentry.org/image-processing/08-edge-detection/"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="https://datacarpentry.org/image-processing/10-challenges/"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>


      
      






<footer>
  <div class="row">
    <div class="col-md-6 copyright" align="left">
	
	Licensed under <a href="https://datacarpentry.org/image-processing/09-contours/">CC-BY 4.0</a> 2018–2019
	by <a href="https://datacarpentry.org/image-processing/09-contours/">The Carpentries</a>
        <br>
        Licensed under <a href="https://datacarpentry.org/image-processing/09-contours/">CC-BY 4.0</a> 2016–2018
	by <a href="http://datacarpentry.org/">Data Carpentry</a>
	
    </div>
    <div class="col-md-6 help-links" align="right">
	
	<a href="https://github.com/datacarpentry/image-processing/edit/gh-pages/_episodes/09-contours.md" data-checker-ignore="">Edit on GitHub</a>
	
	/
	<a href="https://github.com/datacarpentry/image-processing/blob/gh-pages/CONTRIBUTING.md" data-checker-ignore="">Contributing</a>
	/
	<a href="https://github.com/datacarpentry/image-processing/">Source</a>
	/
	<a href="https://github.com/datacarpentry/image-processing/blob/gh-pages/CITATION" data-checker-ignore="">Cite</a>
	/
	<a href="mailto:">Contact</a>
    </div>
  </div>
  <div class="row">
    <div class="col-md-12" align="center">
      Using <a href="https://github.com/carpentries/styles/">The Carpentries style</a>
      version <a href="https://github.com/carpentries/styles/releases/tag/v9.5.3">9.5.3</a>.
    </div>
  </div>
</footer>

      
    </div>
    
<script async="" src="./Contours – Image Processing with Python_files/analytics.js.download"></script><script src="./Contours – Image Processing with Python_files/jquery.min.js.download"></script>
<script src="./Contours – Image Processing with Python_files/bootstrap.min.js.download"></script>
<script src="./Contours – Image Processing with Python_files/lesson.js.download"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-37305346-2', 'auto');
  ga('send', 'pageview');
</script>

  

</body></html>